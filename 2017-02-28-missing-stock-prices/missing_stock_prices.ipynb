{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I came across this problem on [HackerRank](https://www.hackerrank.com/challenges/missing-stock-prices \"Missing Stock Prices Challenge\"). I'm no expert on either data analysis or finance. But when processing historical financial data, it is common to have missing data points for reasons such as: \n",
    "* Incorrect backfilled data (link to Bloomberg article coming soon)\n",
    "* Poor record keeping\n",
    "* Stock exchanges have different holiday schedules. So it becomes an obstacle to perform a time series analysis on securities traded on different exchanges. \n",
    "\n",
    "So sometimes (not always) it makes sense to calculate and predict historical prices.\n",
    "\n",
    "The problem on HackerRank provides a dataset of a stock's highest price each day, with a few points missing. The first line contains the number of rows. Each line contains a date and the highest price that day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "250\n",
    "\n",
    "1/3/2012 16:00:00\t26.96\n",
    "\n",
    "1/4/2012 16:00:00\t27.47\n",
    "\n",
    "1/5/2012 16:00:00\t27.728\n",
    "\n",
    "...\n",
    "\n",
    "12/27/2012 16:00:00\t27.09\n",
    "\n",
    "12/28/2012 16:00:00\t26.9\n",
    "\n",
    "12/31/2012 16:00:00\t26.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Let's start with parsing the input. \n",
    "\n",
    "We don't actually need to use the date in this case since there is only one data point on each trading day. The interval of each price is always exactly one trading day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fileinput\n",
    "\n",
    "file = fileinput.FileInput('input')\n",
    "\n",
    "# This is the number of rows\n",
    "n = int(file.readline())\n",
    "\n",
    "raw_prices = []\n",
    "for i in range(0, n):\n",
    "    date, price = file.readline().split('\\t')\n",
    "    raw_prices.append(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, ```raw_prices``` contains the raw input of prices. We want to distinguish valid prices from the missing ones. Also, the indices (x-axis) will be the independent variable, and the prices (y-axis) will be the dependent variable - target features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# x-axis: date or the index of each data point\n",
    "x = [] # Indices of valid prices\n",
    "x_missing = [] # Indices of missing data\n",
    "\n",
    "# y-axis: prices\n",
    "y = []\n",
    "\n",
    "for i in range(0, n):\n",
    "    if 'Missing' in raw_prices[i]:\n",
    "        x_missing.append(i)\n",
    "    else:\n",
    "        # Valid price\n",
    "        x.append(i)\n",
    "        y.append(float(raw_prices[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At the beginning, I calculated the prices based on 5-day averages. But it wasn't very accurate. So I will try interpolation. We will use a simple [scipy](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.interpolate.UnivariateSpline.html#scipy.interpolate.UnivariateSpline) Univariate Spline for interpolation. We also need [numpy](www.numpy.org) to wrap a list for scipy to process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Interpolation\n",
    "\n",
    "Interpolation works quite well for data points in between existing points. In our case, missing historical stock prices fall perfectly into this category. On the other hand, extrapolation is used for data points **outside** of a given dataset. e.g. stock prices **tomorrow** (extrapolation won't work so well though). [This](https://www.quora.com/What-is-the-difference-between-interpolation-and-extrapolation) is a quick but fantastic explanation that I found helpful.\n",
    "\n",
    "UnivariateSpline simply means using spline interpolation wiht one-dimensional data points. [Spline](https://en.wikipedia.org/wiki/Spline_(mathematics%29) is basically a bunch of piecewise polynomial functions that fit a given dataset. Later on, we can use it to *interpolate* data points. The ```s``` parameter passed to the Spline object is the smoothness factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.56701749439569\n",
      "31.98466008638443\n",
      "32.588716107733376\n",
      "29.401547180365338\n",
      "28.97326520862967\n",
      "28.68606129302796\n",
      "30.523689377232575\n",
      "29.885189408695812\n",
      "29.582872200153187\n",
      "30.867367120670803\n",
      "31.15581794687907\n",
      "31.54592188188132\n",
      "29.668506599317897\n",
      "29.41441268832914\n",
      "29.488051778620097\n",
      "28.925535432472056\n",
      "29.840927304489984\n",
      "28.111090022235476\n",
      "26.845411394867742\n",
      "27.378677906828305\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "import numpy as np\n",
    "\n",
    "spline = UnivariateSpline(np.array(x), np.array(y), s=2)\n",
    "\n",
    "# We start interpolation here\n",
    "for i in x_missing:\n",
    "    print(spline(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The smoothness of a spline function is defined as the number of derivatives that it has that are continuous. A knot is where two piecewise functions are connected. Stock price movements are usually inconsistent. The spline function wouldn't be so smooth with a large number of knots. The 'smoothness factor' dictates how many knots there should be. The more knots there are, the less smooth the function can be overall since knots may be discontinuous. The ```s``` argument refers to how much the residual sum of squares of each existing data point should be minimized. Smaller RSS yields a function that is less smooth. 2 seems to work quite well with the datasets in this case. \n",
    "\n",
    "Thanks for reading! This is a very simple analysis and manipulation on the dataset. I will play around with this dataset a bit more, possibly with Support Vector Machine!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
